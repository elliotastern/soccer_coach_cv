# Training Configuration for RF-DETR

# Model Architecture
model:
  architecture: "detr"  # DETR model
  backbone: "resnet50"  # ResNet backbone
  num_classes: 2  # player, ball
  pretrained: true  # Use pre-trained weights
  hidden_dim: 256
  nheads: 8
  num_encoder_layers: 6
  num_decoder_layers: 6

# Hyperparameters
training:
  batch_size: 24  # Aggressively optimized for A40 (48GB VRAM) - can go higher if needed
  num_epochs: 50
  learning_rate: 0.0001  # 1e-4 as float
  weight_decay: 0.0001  # 1e-4 as float
  warmup_epochs: 5
  gradient_clip: 0.1
  gradient_accumulation_steps: 2  # Accumulate gradients over N batches to reduce memory
  memory_cleanup_frequency: 10  # Cleanup memory every N batches
  mixed_precision: true  # Enable AMP for faster training
  compile_model: true  # Enable torch.compile optimization
  channels_last: true  # Use channels-last memory format for faster convolutions
  cudnn_benchmark: true  # Optimize CUDNN for consistent input sizes
  tf32: true  # Enable TF32 on Ampere GPUs (A40) for faster matmul

# Optimizer
optimizer:
  type: "AdamW"
  lr: 0.0001  # 1e-4 as float
  betas: [0.9, 0.999]
  weight_decay: 0.0001  # 1e-4 as float

# Learning Rate Schedule
lr_schedule:
  type: "cosine"  # cosine annealing
  warmup_epochs: 5
  min_lr: 0.000001  # 1e-6 as float

# Data Augmentation
augmentation:
  train:
    horizontal_flip: 0.5
    color_jitter:
      brightness: 0.2
      contrast: 0.2
      saturation: 0.2
      hue: 0.1
    random_crop: false
    resize_range: [800, 1333]  # DETR standard
  val:
    resize: 1333  # Fixed size for validation

# Dataset
dataset:
  train_path: "/workspace/datasets/train"
  val_path: "/workspace/datasets/val"
  num_workers: 6  # Reduced from 12 to prevent RAM overflow (12 workers Ã— 4 prefetch = 48 batches in memory)
  pin_memory: true
  prefetch_factor: 2  # Reduced from 4 to prevent RAM overflow
  persistent_workers: true  # Keep workers alive between epochs for speed

# Checkpoint Settings
checkpoint:
  save_dir: "models/checkpoints"
  save_frequency: 10  # Save full checkpoint every N epochs (reduced frequency for speed)
  save_every_epoch: true  # Save lightweight checkpoint every epoch (ensures no progress loss)
  save_best: true
  metric: "mAP"  # Mean Average Precision

# Evaluation
evaluation:
  iou_thresholds: [0.5, 0.75]  # IoU thresholds for mAP
  max_detections: 100

# Logging
logging:
  log_dir: "logs"
  tensorboard: true
  print_frequency: 20  # Print every N iterations (reduced for less I/O overhead)
  log_every_n_steps: 50  # Log to TensorBoard less frequently
